{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# тестовое задания для Avito. Проверка гипотез и выбор лучшей модели.\n",
    "\n",
    "(Можно сразу перейти к **заключению** внизу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем предоставленные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.read_csv('data/category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Бытовая электроника|Телефоны|iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Бытовая электроника|Ноутбуки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Бытовая электроника|Телефоны|Samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Бытовая электроника|Планшеты и электронные кни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Бытовая электроника|Игры, приставки и программ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                                               name\n",
       "0            0                Бытовая электроника|Телефоны|iPhone\n",
       "1            1                       Бытовая электроника|Ноутбуки\n",
       "2            2               Бытовая электроника|Телефоны|Samsung\n",
       "3            3  Бытовая электроника|Планшеты и электронные кни...\n",
       "4            4  Бытовая электроника|Игры, приставки и программ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train.csv', index_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Картина</td>\n",
       "      <td>Гобелен. Размеры 139х84см.</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Стулья из прессованной кожи</td>\n",
       "      <td>Продам недорого 4 стула из светлой прессованно...</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Домашняя мини баня</td>\n",
       "      <td>Мини баня МБ-1(мини сауна), предназначена для ...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Эксклюзивная коллекция книг \"Трансаэро\" + подарок</td>\n",
       "      <td>Продам эксклюзивную коллекцию книг, выпущенную...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ноутбук aser</td>\n",
       "      <td>Продаётся ноутбук ACER e5-511C2TA. Куплен в ко...</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "item_id                                                      \n",
       "0                                                  Картина   \n",
       "1                              Стулья из прессованной кожи   \n",
       "2                                       Домашняя мини баня   \n",
       "3        Эксклюзивная коллекция книг \"Трансаэро\" + подарок   \n",
       "4                                             Ноутбук aser   \n",
       "\n",
       "                                               description    price  \\\n",
       "item_id                                                               \n",
       "0                               Гобелен. Размеры 139х84см.   1000.0   \n",
       "1        Продам недорого 4 стула из светлой прессованно...   1250.0   \n",
       "2        Мини баня МБ-1(мини сауна), предназначена для ...  13000.0   \n",
       "3        Продам эксклюзивную коллекцию книг, выпущенную...   4000.0   \n",
       "4        Продаётся ноутбук ACER e5-511C2TA. Куплен в ко...  19000.0   \n",
       "\n",
       "         category_id  \n",
       "item_id               \n",
       "0                 19  \n",
       "1                 22  \n",
       "2                 37  \n",
       "3                 43  \n",
       "4                  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data/test.csv', index_col='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489517</th>\n",
       "      <td>Стоик журнальный сталь</td>\n",
       "      <td>продам журнальный столик изготавливаю столы из...</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489518</th>\n",
       "      <td>iPhone 5 64Gb</td>\n",
       "      <td>Телефон в хорошем состоянии. Комплект, гаранти...</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489519</th>\n",
       "      <td>Утеплитель</td>\n",
       "      <td>ТЕПЛОПЕЛЕН-ЛИДЕР ТЕПЛА!!! Толщина утеплителя :...</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489520</th>\n",
       "      <td>Пальто демисезонное</td>\n",
       "      <td>Продам пальто женское (букле) в отличном состо...</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489521</th>\n",
       "      <td>Samsung syncmaster T200N</td>\n",
       "      <td>Условно рабочий, проблема в панели настройки м...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  \\\n",
       "item_id                             \n",
       "489517     Стоик журнальный сталь   \n",
       "489518              iPhone 5 64Gb   \n",
       "489519                 Утеплитель   \n",
       "489520        Пальто демисезонное   \n",
       "489521   Samsung syncmaster T200N   \n",
       "\n",
       "                                               description    price  \n",
       "item_id                                                              \n",
       "489517   продам журнальный столик изготавливаю столы из...  10000.0  \n",
       "489518   Телефон в хорошем состоянии. Комплект, гаранти...  12500.0  \n",
       "489519   ТЕПЛОПЕЛЕН-ЛИДЕР ТЕПЛА!!! Толщина утеплителя :...    250.0  \n",
       "489520   Продам пальто женское (букле) в отличном состо...   1700.0  \n",
       "489521   Условно рабочий, проблема в панели настройки м...   1000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделение признаков из текста\n",
    "- считаем количество латинских букв\n",
    "- считаем длину\n",
    "- избавляемся от знаков препинания\n",
    "- Все встречающиеся слова приводим к нормальной форме\n",
    "- кодируем в вектора через CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "english_check = re.compile(r'[a-zA-Z]')\n",
    "\n",
    "def count_eng(text):\n",
    "    counter = 0\n",
    "    for c in text:\n",
    "        if english_check.match(c):\n",
    "            counter += 1\n",
    "            \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['title_eng_count'] = data_train['title'].apply(count_eng)\n",
    "\n",
    "data_train['descr_eng_count'] = data_train['description'].apply(count_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['title_len'] = data_train['title'].apply(len)\n",
    "\n",
    "data_train['descr_len'] = data_train['description'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2 as morphy\n",
    "import string\n",
    "\n",
    "morpher = morphy.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=100000)\n",
    "def get_normal_form (word):\n",
    "    return morpher.normal_forms(word)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalizer(text):\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))).lower()\n",
    "    words = text.split()\n",
    "    normalized_text = ''\n",
    "    for word in words:\n",
    "        normalized_text += get_normal_form(word) + ' '\n",
    "        \n",
    "    return normalized_text.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.64 s, sys: 4.27 s, total: 10.9 s\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with Pool(processes=4) as pool:\n",
    "    data_train['title_norm'] = pool.map(text_normalizer, data_train.title)\n",
    "    data_train['desct_norm'] = pool.map(text_normalizer, data_train.description)\n",
    "    \n",
    "    data_test['title_norm'] = pool.map(text_normalizer, data_test.title)\n",
    "    data_test['desct_norm'] = pool.map(text_normalizer, data_test.description)\n",
    "    pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 s, sys: 2.09 s, total: 46.1 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_vectorizer = CountVectorizer(binary=True)\n",
    "title_features_train = title_vectorizer.fit_transform(data_train.title)\n",
    "title_features_test = title_vectorizer.transform(data_test.title)\n",
    "\n",
    "descr_vectorizer = CountVectorizer(binary=True)\n",
    "description_features_train = descr_vectorizer.fit_transform(data_train.description)\n",
    "description_features_test = descr_vectorizer.transform(data_test.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Числовые признаки\n",
    "Отшкалируем числовые признаки для использования в метрических алгоритмах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_columns = ['price', 'title_eng_count', 'descr_eng_count', 'title_len', 'descr_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "num_features_scaled_train = scaler.fit_transform(data_train.loc[:, num_features_columns])\n",
    "num_features_scaled_test = scaler.transform(data_test.loc[:, num_features_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор модели и обучение\n",
    "Протестируем несколько моделей и выберем лучшую.\n",
    "#### Модели:\n",
    "- Logistic regression\n",
    "- Desision tree\n",
    "- Random forest\n",
    "\n",
    "#### Метрики:\n",
    "- Accuracy\n",
    "- LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.hstack((title_features_train, description_features_train, data_train.loc[:, num_features_columns]))\n",
    "features_scaled = sp.hstack((title_features_train, description_features_train, num_features_scaled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, data_train['category_id'], \n",
    "                                              random_state=648, test_size=0.25, shuffle=True)\n",
    "\n",
    "X_s_train, X_s_val, y_s_train, y_s_val = train_test_split(features_scaled, data_train['category_id'], \n",
    "                                         random_state=648, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Accuracy: 0.719578362477529\n",
      "LogLoss: 9.684881752096686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy: 0.7671596666121915\n",
      "LogLoss: 3.2510848761097653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy: 0.8806095767282236\n",
      "LogLoss: 0.4759405998050163\n",
      "CPU times: user 2h 36min 3s, sys: 34.5 s, total: 2h 36min 38s\n",
      "Wall time: 2h 37min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "for clf in (tree, forest):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_val)\n",
    "    y_hat_proba = clf.predict_proba(X_val)\n",
    "    print(str(clf))\n",
    "    print('Accuracy: ' + str(accuracy_score(y_val, y_hat)))\n",
    "    print('LogLoss: ' + str(log_loss(y_val, y_hat_proba)))\n",
    "\n",
    "#То же самое для logreg только с отшкалированными данными\n",
    "logreg.fit(X_s_train, y_s_train)\n",
    "y_hat = logreg.predict(X_s_val)\n",
    "y_hat_proba = logreg.predict_proba(X_s_val)\n",
    "print(str(logreg))\n",
    "print('Accuracy: ' + str(accuracy_score(y_s_val, y_hat)))\n",
    "print('LogLoss: ' + str(log_loss(y_s_val, y_hat_proba))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что с большим отрывом лучший результат показала логистическая регрессия. Попробуем улучшить результат, изменив некоторые параметры модели:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Изменим параметр CountVectorizer binary на False. Раньше признаком являлось просто вхождение слова в текст, теперь попробуем считать количество вхождений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.1 s, sys: 1.33 s, total: 43.4 s\n",
      "Wall time: 43.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_vectorizer = CountVectorizer(binary=False)\n",
    "title_features_train = title_vectorizer.fit_transform(data_train.title)\n",
    "title_features_test = title_vectorizer.transform(data_test.title)\n",
    "\n",
    "descr_vectorizer = CountVectorizer(binary=False)\n",
    "description_features_train = descr_vectorizer.fit_transform(data_train.description)\n",
    "description_features_test = descr_vectorizer.transform(data_test.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "num_features_train = scaler.fit_transform(data_train.loc[:, num_features_columns])\n",
    "num_features_test = scaler.transform(data_test.loc[:, num_features_columns])\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "title_features_train = scaler.fit_transform(title_features_train)\n",
    "title_features_test = scaler.transform(title_features_train)\n",
    "\n",
    "description_features_train = scaler.fit_transform(description_features_train)\n",
    "description_features_test = scaler.transform(description_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.hstack((title_features_train, description_features_train, num_features_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, data_train['category_id'], \n",
    "                                              random_state=648, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy: 0.790496813204772\n",
      "LogLoss: 1.8242081826090177\n",
      "CPU times: user 2h 52min 56s, sys: 39.4 s, total: 2h 53min 35s\n",
      "Wall time: 2h 55min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat = logreg.predict(X_val)\n",
    "y_hat_proba = logreg.predict_proba(X_val)\n",
    "print(str(logreg))\n",
    "print('Accuracy: ' + str(accuracy_score(y_val, y_hat)))\n",
    "print('LogLoss: ' + str(log_loss(y_val, y_hat_proba))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.3 s, sys: 3.9 s, total: 51.2 s\n",
      "Wall time: 54.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_vectorizer = CountVectorizer(binary=False)\n",
    "title_features_train = title_vectorizer.fit_transform(data_train.title)\n",
    "title_features_test = title_vectorizer.transform(data_test.title)\n",
    "\n",
    "descr_vectorizer = CountVectorizer(binary=False)\n",
    "description_features_train = descr_vectorizer.fit_transform(data_train.description)\n",
    "description_features_test = descr_vectorizer.transform(data_test.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_unscaled = sp.hstack((title_features_train, description_features_train, data_train.loc[:, num_features_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features_unscaled, data_train['category_id'], \n",
    "                                              random_state=648, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy: 0.6341640790978919\n",
      "LogLoss: 1.7574700414389088\n",
      "CPU times: user 56min 29s, sys: 15 s, total: 56min 45s\n",
      "Wall time: 57min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat = logreg.predict(X_val)\n",
    "y_hat_proba = logreg.predict_proba(X_val)\n",
    "print(str(logreg))\n",
    "print('Accuracy: ' + str(accuracy_score(y_val, y_hat)))\n",
    "print('LogLoss: ' + str(log_loss(y_val, y_hat_proba))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_columns = ['title_eng_count', 'descr_eng_count', 'title_len', 'descr_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_scaled = np.array((data_train['price'] - np.mean(data_train['price'])) / np.std(data_train['price'])).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489517, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.hstack((title_features_train, description_features_train,\n",
    "                               data_train.loc[:, num_features_columns], price_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, data_train['category_id'], \n",
    "                                              random_state=648, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy: 0.790496813204772\n",
      "LogLoss: 1.8242081826090177\n",
      "CPU times: user 2h 59min 52s, sys: 1min 27s, total: 3h 1min 19s\n",
      "Wall time: 3h 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat = logreg.predict(X_val)\n",
    "y_hat_proba = logreg.predict_proba(X_val)\n",
    "print(str(logreg))\n",
    "print('Accuracy: ' + str(accuracy_score(y_val, y_hat)))\n",
    "print('LogLoss: ' + str(log_loss(y_val, y_hat_proba))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy: 0.7198398431116195\n",
      "LogLoss: 9.676127092712614\n",
      "CPU times: user 57min 24s, sys: 18.8 s, total: 57min 43s\n",
      "Wall time: 58min 44s\n"
     ]
    }
   ],
   "source": [
    "treeime\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "y_hat = tree.predict(X_val)\n",
    "y_hat_proba = tree.predict_proba(X_val)\n",
    "print(str(logreg))\n",
    "print('Accuracy: ' + str(accuracy_score(y_val, y_hat)))\n",
    "print('LogLoss: ' + str(log_loss(y_val, y_hat_proba))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, лучший возможный результат без бустинга получен на линейной модели. Теперь попробуем воспользоваться xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 1.48 s, total: 35.3 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_vectorizer = CountVectorizer(binary=True)\n",
    "title_features_train = title_vectorizer.fit_transform(data_train.title)\n",
    "\n",
    "descr_vectorizer = CountVectorizer(binary=True)\n",
    "description_features_train = descr_vectorizer.fit_transform(data_train.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_columns = ['price', 'title_eng_count', 'descr_eng_count', 'title_len', 'descr_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "num_features_scaled_train = scaler.fit_transform(data_train.loc[:, num_features_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.hstack((title_features_train, description_features_train, num_features_scaled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, data_train['category_id'], \n",
    "                                              random_state=648, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем две модели:\n",
    "- логистическую регрессию (с фичами показавшими лучший результат)\n",
    "- random forest (с лучшими для линейной модели фичами, и с другим набором (субъективно более информативным))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': category.shape[0],\n",
    "    'booster': 'gblinear',\n",
    "    \n",
    "    'alpha': 0.5,\n",
    "    \n",
    "    'seed': 648,\n",
    "    'nthread': 2,\n",
    "    'eval_metric':'merror'\n",
    "}\n",
    "\n",
    "num_rounds = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, data_train['category_id'], \n",
    "                                              random_state=648, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapiskotin/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.979574\teval-merror:0.97958\n",
      "Multiple eval metrics have been passed: 'eval-merror' will be used for early stopping.\n",
      "\n",
      "Will train until eval-merror hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.979574\teval-merror:0.97958\n",
      "\n",
      "CPU times: user 3min 10s, sys: 1.73 s, total: 3min 12s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtrain = xgb.DMatrix( X_train, label=y_train)\n",
    "dtest = xgb.DMatrix( X_val, label=y_val,)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "eval_res ={}\n",
    "gbdt = xgb.train(xgb_params, dtrain,\n",
    "                 num_rounds, watchlist,\n",
    "                 early_stopping_rounds=5,\n",
    "                 verbose_eval=10,\n",
    "                 evals_result=eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': category.shape[0],\n",
    "    'max_depth': 7,\n",
    "    'eta': 0.12,\n",
    "    'booster': 'gbtree',\n",
    "    \n",
    "    'alpha': 2.0,\n",
    "    'lambda': 0.1,\n",
    "    \n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'colsample_bylevel': 1.0,\n",
    "    \n",
    "    'seed': 648,\n",
    "    'nthread': 2,\n",
    "    'eval_metric':'merror'\n",
    "}\n",
    "\n",
    "num_rounds = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.37711\teval-merror:0.380176\n",
      "Multiple eval metrics have been passed: 'eval-merror' will be used for early stopping.\n",
      "\n",
      "Will train until eval-merror hasn't improved in 5 rounds.\n",
      "[5]\ttrain-merror:0.221182\teval-merror:0.231778\n",
      "[10]\ttrain-merror:0.202401\teval-merror:0.215852\n",
      "[15]\ttrain-merror:0.191825\teval-merror:0.207599\n",
      "[20]\ttrain-merror:0.184487\teval-merror:0.202002\n",
      "[25]\ttrain-merror:0.1781\teval-merror:0.197238\n",
      "[30]\ttrain-merror:0.17247\teval-merror:0.193063\n",
      "[35]\ttrain-merror:0.166875\teval-merror:0.18914\n",
      "[40]\ttrain-merror:0.162332\teval-merror:0.18548\n",
      "[45]\ttrain-merror:0.158186\teval-merror:0.182799\n",
      "[50]\ttrain-merror:0.15409\teval-merror:0.179449\n",
      "[55]\ttrain-merror:0.150489\teval-merror:0.177186\n",
      "[60]\ttrain-merror:0.147008\teval-merror:0.174832\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1110\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtrain = xgb.DMatrix( X_train, label=y_train)\n",
    "dtest = xgb.DMatrix( X_val, label=y_val,)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "eval_res ={}\n",
    "gbdt = xgb.train(xgb_params, dtrain,\n",
    "                 num_rounds, watchlist,\n",
    "                 early_stopping_rounds=5,\n",
    "                 verbose_eval=5,\n",
    "                 evals_result=eval_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключение:\n",
    "- Лучшая модель - Логистическая регрессия\n",
    "- Лучший способ кодирования признаков из текста - CountVectorizer(binary=True) -> вхождение слова в название/описание важнее количества его вхождений\n",
    "- бустинг не дал улучшения результата (по крайней мере, в условиях ограниченного времени и мощностей)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
